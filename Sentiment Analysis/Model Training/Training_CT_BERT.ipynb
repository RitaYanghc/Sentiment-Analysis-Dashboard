{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1U1C9vdf_-I",
    "outputId": "c5f40687-21dd-48b6-cf85-6b86b1a97dbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\")\n",
    "os.chdir(\"/content/gdrive/My Drive/BertTweet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpjdDol3BEax",
    "outputId": "076b2238-4c45-47eb-afca-2fa3d314a2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
      "Collecting transformers==3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 7.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 31.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 44.3MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 45.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (20.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (2.4.7)\n",
      "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc2 transformers-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install transformers==3.1.0\n",
    "import re\n",
    "import emoji\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from transformers import (\n",
    "   AutoConfig,\n",
    "   AutoTokenizer,\n",
    "   TFAutoModelForSequenceClassification,\n",
    "   AdamW,\n",
    "   InputExample,\n",
    "   InputFeatures\n",
    ")\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABgJS0-w7QO8"
   },
   "source": [
    "# **Data Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZ_3BDmUCFAA",
    "outputId": "d8581187-1d1b-43b1-96a2-a53c2f3f1b09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"annotated_tweets/*.csv\"\n",
    "csv_list = glob.glob(path)\n",
    "len(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtM6tUatLF3c",
    "outputId": "eb8667bc-7ecd-4a4e-8464-3e7061a7f179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annotated_tweets/SemEval2017-task4-test.csv',\n",
       " 'annotated_tweets/SemEval2017-task4-dev.csv',\n",
       " 'annotated_tweets/twitter-2013train-A.csv',\n",
       " 'annotated_tweets/twitter-2016train-A.csv',\n",
       " 'annotated_tweets/twitter-2014test-A.csv',\n",
       " 'annotated_tweets/twitter-2013test-A.csv',\n",
       " 'annotated_tweets/twitter-2016devtest-A.csv',\n",
       " 'annotated_tweets/twitter-2016test-A.csv',\n",
       " 'annotated_tweets/twitter-2015test-A.csv',\n",
       " 'annotated_tweets/twitter-2013dev-A.csv',\n",
       " 'annotated_tweets/twitter-2016dev-A.csv',\n",
       " 'annotated_tweets/twitter-2015train-A.csv']"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "h24P-5HNCdCw",
    "outputId": "a9bdf868-b8df-496f-e237-a8ee7c33d735"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>801989080477154944</td>\n",
       "      <td>neutral</td>\n",
       "      <td>#ArianaGrande Ari By Ariana Grande 80% Full ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>801989272341453952</td>\n",
       "      <td>positive</td>\n",
       "      <td>Ariana Grande KIIS FM Yours Truly CD listening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>801990978424962944</td>\n",
       "      <td>positive</td>\n",
       "      <td>Ariana Grande White House Easter Egg Roll in W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>801996232553963008</td>\n",
       "      <td>positive</td>\n",
       "      <td>#CD #Musics Ariana Grande Sweet Like Candy 3.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>801998343442407040</td>\n",
       "      <td>neutral</td>\n",
       "      <td>SIDE TO SIDE 😘 @arianagrande #sidetoside #aria...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  ...                                             Tweets\n",
       "0      0  ...  #ArianaGrande Ari By Ariana Grande 80% Full ht...\n",
       "1      1  ...  Ariana Grande KIIS FM Yours Truly CD listening...\n",
       "2      2  ...  Ariana Grande White House Easter Egg Roll in W...\n",
       "3      3  ...  #CD #Musics Ariana Grande Sweet Like Candy 3.4...\n",
       "4      4  ...  SIDE TO SIDE 😘 @arianagrande #sidetoside #aria...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame()\n",
    "for f in csv_list:\n",
    "  temp = pd.concat([temp,pd.read_csv(f,sep='\\t', header=None)])\n",
    "temp = temp.drop(axis=1, columns=3)\n",
    "temp.columns = ['id','Sentiment','Tweets']\n",
    "temp = temp.reset_index()\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "48013g4pJoHQ",
    "outputId": "80670929-a485-49aa-df00-4575d5564a8c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hairspray Live! Previews at the Macy's Thanksgiving Day Parade! https://t.co/GaFTqInolL #arianagrande #televisionnbc\""
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.Tweets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RBneRBD3Pjqq",
    "outputId": "c16a3b46-9372-43fe-b7ce-b92380f8bd5a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"hairspray live previews at the macy's thanksgiving day parade arianagrande televisionnbc\""
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.Tweets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dk1wDcwMFLi3"
   },
   "outputs": [],
   "source": [
    "temp.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjFyHFh07Gqs",
    "outputId": "c47e0dd6-5665-458c-8b76-ca40fee547d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82621 entries, 0 to 82620\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   index      82621 non-null  int64 \n",
      " 1   id         82621 non-null  int64 \n",
      " 2   Sentiment  82621 non-null  object\n",
      " 3   Tweets     82621 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweet = pd.read_csv('data.csv',index_col=0)\n",
    "df_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4i4vNkUBCSp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_html(tweet):\n",
    "  tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "  return tweet\n",
    "\n",
    "def clean_hashtag(tweet):\n",
    "  tweet = tweet.replace(\"#\", \" \").replace(\"_\", \" \")\n",
    "  return tweet\n",
    "\n",
    "def clean_punc(tweet):\n",
    "  tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
    "  return tweet\n",
    "\n",
    "def replace_emoji(text):\n",
    "    text = text.lower().strip()\n",
    "    text = emoji.demojize(text, delimiters=(' ', ' '))\n",
    "    return text \n",
    "\n",
    "def replace_at(text):\n",
    "  text = text.strip()\n",
    "  text = text.replace(\"@\",\"at \")\n",
    "  return text\n",
    "\n",
    "def lower_case(tweet):\n",
    "  tweet = tweet.lower()\n",
    "  return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2h1ERjaGBcQi",
    "outputId": "ecb7041a-c680-4b65-f189-ab9e74390bba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i,row in df_tweet.iterrows():\n",
    "  df_tweet['Tweets'][i] = clean_hashtag(df_tweet['Tweets'][i])\n",
    "  df_tweet['Tweets'][i] = clean_html(df_tweet['Tweets'][i])\n",
    "  df_tweet['Tweets'][i] = clean_punc(df_tweet['Tweets'][i])\n",
    "  df_tweet['Tweets'][i] = replace_emoji(df_tweet['Tweets'][i])\n",
    "  df_tweet['Tweets'][i] = lower_case(df_tweet['Tweets'][i])\n",
    "  df_tweet['Tweets'][i] = replace_at(df_tweet['Tweets'][i])\n",
    "  \n",
    "\n",
    "df_tweet['Tweets']=df_tweet[\"Tweets\"].drop_duplicates()\n",
    "df_tweet = df_tweet[df_tweet['Tweets'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2R1mwTbJQBu",
    "outputId": "27c0de44-4d02-45a9-94f2-7d9be8e4770a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61149 entries, 0 to 82502\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   index      61149 non-null  int64 \n",
      " 1   id         61149 non-null  int64 \n",
      " 2   Sentiment  61149 non-null  object\n",
      " 3   Tweets     61149 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ge_9vJ70Kq46",
    "outputId": "72449c1a-d571-4be8-c975-1e44d8247d9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     27837\n",
       "positive    21829\n",
       "negative    11483\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OcdqYh3IjXs"
   },
   "outputs": [],
   "source": [
    "df_tweet.to_csv(\"tweets_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "uP-rhHh67dGp",
    "outputId": "be49442d-072d-4862-cb32-78089c523fa6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i'm done writing code for the week looks like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>dec 21st 2012 will be know not as the end of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>at macmiller hate my life because i can't see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>checked out our lady peace at bluesfest tonigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>hello from the foundation trekkers we're up in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                          full_text\n",
       "0  positive  i'm done writing code for the week looks like ...\n",
       "1   neutral  dec 21st 2012 will be know not as the end of t...\n",
       "2  negative  at macmiller hate my life because i can't see ...\n",
       "3  positive  checked out our lady peace at bluesfest tonigh...\n",
       "4  positive  hello from the foundation trekkers we're up in..."
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tweets_data.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l5UG0ZBTpuo"
   },
   "source": [
    "**Dataset preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvZINUj6BSnB"
   },
   "outputs": [],
   "source": [
    "#Split the datset into validation, test, train sets by 1:1:5\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_test, dev_data = train_test_split(data,test_size =1/7,random_state =42, shuffle=True)\n",
    "train_data, test_data = train_test_split(train_test,test_size =1/6,random_state =42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Xjd63CJsqNY",
    "outputId": "941d27cd-7947-46ed-9bdc-295dc9808888"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#use numbers to represent sentiments\n",
    "def sentiment_label (Sentiment):\n",
    "   if Sentiment == \"positive\":\n",
    "       return 2\n",
    "   elif Sentiment ==\"negative\" :\n",
    "       return 0\n",
    "   else:\n",
    "       return  1\n",
    "train_data['Sentiment'] = train_data['Sentiment'].apply(sentiment_label)\n",
    "dev_data['Sentiment'] = dev_data['Sentiment'].apply(sentiment_label)\n",
    "test_data['Sentiment'] = test_data['Sentiment'].apply(sentiment_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "120a22ff51a64b41a76f3a5f2a818caf",
      "3fc5718a054c43d5b6644aef9e69b42a",
      "17bd8df397a0459a8e5e577ad4705463",
      "b3d42861496b4b03bfe2d5b2a32b4c9e",
      "7eda40dd90694167a4f9f476356b4487",
      "7d669d1ac02c491c877426c4c4f1ea75",
      "5ac8c2735ef44c36948f63a0bf37b285",
      "6014e60b9b5d4337b2c94c372c7f53f5",
      "b98b32da9cc84d55a5d85eb7d2940717",
      "4da1f5737edf487bbd8f1c4f280a16ae",
      "5bc583f88db94e6385660975ec21df00",
      "ccf6ae8bd9af406fb0eb91d2a18d062e",
      "f1132d7d1c7d4402b3a6fdc86e9f4e44",
      "b816512135bb42a08a63e5a45d22efee",
      "062d3b870c3a4d2c96b7588ebec4f917",
      "28242db0cd1044a9b062f3de4f8ce72e"
     ]
    },
    "id": "hC6iLYsd7v_Z",
    "outputId": "54ab88f8-2385-45e6-e224-083f64ad66d5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120a22ff51a64b41a76f3a5f2a818caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=421.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98b32da9cc84d55a5d85eb7d2940717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose model\n",
    "# @markdown >The default model is <i><b>COVID-Twitter-BERT</b></i>. You can however choose <i><b>BERT Base</i></b> or <i><b>BERT Large</i></b> to compare these models to the <i><b>COVID-Twitter-BERT</i></b>. All these three models will be initiated with a random classification layer. If you go directly to the Predict-cell after having compiled the model, you will see that it still runs the predition. However the output will be random. The training steps below will finetune this for the specific task. <br /><br /> \n",
    "model_name = 'digitalepidemiologylab/covid-twitter-bert' #@param [\"digitalepidemiologylab/covid-twitter-bert\", \"bert-large-uncased\", \"bert-base-uncased\"]\n",
    "\n",
    "# Initialise tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AkzRsKEGGfJ"
   },
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
    "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "  \n",
    "  return train_InputExamples, validation_InputExamples\n",
    "\n",
    "\n",
    "\n",
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'full_text'\n",
    "LABEL_COLUMN = 'Sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MeFZCXe3Od4F",
    "outputId": "76e9560b-a15c-4dc1-f097-c60fca0ad568"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train_data, dev_data, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "train = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train = train.shuffle(100).batch(6)\n",
    "\n",
    "validation = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation = validation.batch(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkfxSLjqUEmV"
   },
   "source": [
    "**Model Creating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjjku_x-KH8g"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "\n",
    "def create_model():\n",
    "  config = AutoConfig.from_pretrained(model_name, num_labels=3)\n",
    "  model = TFAutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      optimizer=opt, metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdab9v0K_dOG",
    "outputId": "cf099e27-6c6b-4af6-e93f-4d7191c4de28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert were not used when initializing TFBertForSequenceClassification: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['dropout_147', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmLjBrxoULZ-"
   },
   "source": [
    "**Training Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_EUqkqLVxpW",
    "outputId": "1d2eb333-de01-4bae-e05c-8b835c1460b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7279/7279 [==============================] - 4157s 567ms/step - loss: 0.7115 - accuracy: 0.6740 - val_loss: 0.6285 - val_accuracy: 0.7169\n"
     ]
    }
   ],
   "source": [
    "train_data_size = len(train_data)\n",
    "dev_data_size = len(dev_data)\n",
    "batch_size = 6\n",
    "epochs = 2\n",
    "\n",
    "history = model.fit_generator(train, \n",
    "                    validation_data=validation, \n",
    "                    steps_per_epoch = int(train_data_size / batch_size),\n",
    "                    epochs=2, \n",
    "                    verbose =1,\n",
    "                    validation_steps = int(dev_data_size /batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvGgA96R1Emg",
    "outputId": "c630a5c7-f910-4174-93d8-a03257eecd20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "_, test_InputExamples = convert_data_to_examples(dev_data, test_data, 'full_text', 'Sentiment')\n",
    "\n",
    "test = convert_examples_to_tf_dataset(list(test_InputExamples), tokenizer)\n",
    "test = test.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ioXxXiDwikLO",
    "outputId": "accf8814-f477-453d-e226-be940c4aa4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8736/8736 [==============================] - 477s 55ms/step - loss: 0.6324 - accuracy: 0.7184\n",
      "Loss: 0.6324429512023926\n",
      "Accuracy: 0.718406617641449\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Yzlq66Gq5P3"
   },
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4AVjqXpq-Zt"
   },
   "outputs": [],
   "source": [
    "#after loading tokenizer and model\n",
    "\n",
    "def format_prediction(ds):\n",
    "  pred_sentences = []\n",
    "  pred_sentences = list(ds['full_text'])\n",
    "  #for index,row in ds:\n",
    "    #pred_sentences.append(row['Tweets'])\n",
    "  tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "  tf_outputs = model(tf_batch)\n",
    "  tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "  label = tf.argmax(tf_predictions, axis=1)\n",
    "  label = label.numpy()\n",
    "  new = pd.concat([ds,pd.DataFrame(label,columns=['pred'])],axis=1)\n",
    "  return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLnOhloZn3tS"
   },
   "outputs": [],
   "source": [
    "ts = pd.read_csv('TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1oKbSawofqn",
    "outputId": "2d2ec429-bb1f-4080-8a86-78b553a6a8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 22132 to 44693\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentiment  900 non-null    int64 \n",
      " 1   full_text  900 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 21.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOMoLoT7Ef6E"
   },
   "outputs": [],
   "source": [
    "pred = format_prediction(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvGh-e2gAlw8"
   },
   "outputs": [],
   "source": [
    "labels = ['Negative','Neutral','Positive']\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(pred['Sentiment'],pred['pred'], target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYd-VId8q-_U"
   },
   "source": [
    "# **Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiJbL7FuF2xC"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"ct_bert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Lb0RX_WDblL"
   },
   "source": [
    "# **Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUdXCkFvt3iP",
    "outputId": "e5162552-4ca3-4c67-f893-307d899dfd93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ct_bert were not used when initializing TFBertForSequenceClassification: ['dropout_73']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at ct_bert and are newly initialized: ['dropout_221']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"ct_bert\")\n",
    "# Choose model\n",
    "# @markdown >The default model is <i><b>COVID-Twitter-BERT</b></i>. You can however choose <i><b>BERT Base</i></b> or <i><b>BERT Large</i></b> to compare these models to the <i><b>COVID-Twitter-BERT</i></b>. All these three models will be initiated with a random classification layer. If you go directly to the Predict-cell after having compiled the model, you will see that it still runs the predition. However the output will be random. The training steps below will finetune this for the specific task. <br /><br /> \n",
    "model_name = 'digitalepidemiologylab/covid-twitter-bert' #@param [\"digitalepidemiologylab/covid-twitter-bert\", \"bert-large-uncased\", \"bert-base-uncased\"]\n",
    "\n",
    "# Initialise tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftXp_TIoCiaY"
   },
   "outputs": [],
   "source": [
    "#after loading tokenizer and model\n",
    "labels = ['Negative','Positive']\n",
    "def format_prediction(ds):\n",
    "  pred_sentences = []\n",
    "  pred_sentences = list(ds['Tweets'])\n",
    "  #for index,row in ds:\n",
    "    #pred_sentences.append(row['Tweets'])\n",
    "  tf_batch = tokenizer(pred_sentences, max_length=280, padding=True, truncation=True, return_tensors='tf')\n",
    "  tf_outputs = model(tf_batch)\n",
    "  tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "  label = tf.argmax(tf_predictions, axis=1)\n",
    "  label = label.numpy()\n",
    "  new = pd.concat([ds,pd.DataFrame(label,columns=['pred'])],axis=1)\n",
    "  return new\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "3pRtvfwJq0Gf",
    "outputId": "d673fe20-8d80-42fa-f72b-f838e2b07c2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri May 01 16:50:50 +0000 2020</td>\n",
       "      <td>Before, during and after #COVID19, achieving #...</td>\n",
       "      <td>1256264828743757826</td>\n",
       "      <td>{'id': 'b71fac2ee9792cbe', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat May 02 13:17:34 +0000 2020</td>\n",
       "      <td>The Pioneer DDJ-SZ is one of my favorite decks...</td>\n",
       "      <td>1256573546886815744</td>\n",
       "      <td>{'id': '36763957ba75d166', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sat May 02 16:23:44 +0000 2020</td>\n",
       "      <td>We designed a vulnerability survey to provide ...</td>\n",
       "      <td>1256620399753859076</td>\n",
       "      <td>{'id': '000c69ad123213a8', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sat May 02 17:43:03 +0000 2020</td>\n",
       "      <td>Distant But Connected.\\n\\nJust like this, we a...</td>\n",
       "      <td>1256640360731860992</td>\n",
       "      <td>{'id': '272983f6b52c196e', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat May 02 18:39:40 +0000 2020</td>\n",
       "      <td>More lines today.  Looks like social distancin...</td>\n",
       "      <td>1256654607281008641</td>\n",
       "      <td>{'id': 'bc38440673d47ddf', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41561</th>\n",
       "      <td>Mon Jun 01 01:46:06 +0000 2020</td>\n",
       "      <td>I am the same all year round always about our ...</td>\n",
       "      <td>1267271170312867840</td>\n",
       "      <td>{'id': '4de072969805ac41', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41562</th>\n",
       "      <td>Wed May 27 12:11:52 +0000 2020</td>\n",
       "      <td>15-17 May 2020 we #livestreamed the first ever...</td>\n",
       "      <td>1265616710046035969</td>\n",
       "      <td>{'id': '3eb2c704fe8a50cb', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41563</th>\n",
       "      <td>Thu May 07 03:15:56 +0000 2020</td>\n",
       "      <td>How we will all feel when isolation is over. #...</td>\n",
       "      <td>1258234081504112640</td>\n",
       "      <td>{'id': '01864a8a64df9dc4', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41564</th>\n",
       "      <td>Fri May 22 17:05:53 +0000 2020</td>\n",
       "      <td>❤❤ I challenge you to #SaveTheWorld from #Covi...</td>\n",
       "      <td>1263878763747717120</td>\n",
       "      <td>{'id': '01a9a39529b27f36', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41565</th>\n",
       "      <td>Mon May 04 00:10:43 +0000 2020</td>\n",
       "      <td>That's not necessarily true, Mr Walley.\\n\\n#co...</td>\n",
       "      <td>1257100305180823553</td>\n",
       "      <td>{'id': '927de37f5169864a', 'url': 'https://api...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41566 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 time  ...                                              place\n",
       "0      Fri May 01 16:50:50 +0000 2020  ...  {'id': 'b71fac2ee9792cbe', 'url': 'https://api...\n",
       "1      Sat May 02 13:17:34 +0000 2020  ...  {'id': '36763957ba75d166', 'url': 'https://api...\n",
       "2      Sat May 02 16:23:44 +0000 2020  ...  {'id': '000c69ad123213a8', 'url': 'https://api...\n",
       "3      Sat May 02 17:43:03 +0000 2020  ...  {'id': '272983f6b52c196e', 'url': 'https://api...\n",
       "4      Sat May 02 18:39:40 +0000 2020  ...  {'id': 'bc38440673d47ddf', 'url': 'https://api...\n",
       "...                               ...  ...                                                ...\n",
       "41561  Mon Jun 01 01:46:06 +0000 2020  ...  {'id': '4de072969805ac41', 'url': 'https://api...\n",
       "41562  Wed May 27 12:11:52 +0000 2020  ...  {'id': '3eb2c704fe8a50cb', 'url': 'https://api...\n",
       "41563  Thu May 07 03:15:56 +0000 2020  ...  {'id': '01864a8a64df9dc4', 'url': 'https://api...\n",
       "41564  Fri May 22 17:05:53 +0000 2020  ...  {'id': '01a9a39529b27f36', 'url': 'https://api...\n",
       "41565  Mon May 04 00:10:43 +0000 2020  ...  {'id': '927de37f5169864a', 'url': 'https://api...\n",
       "\n",
       "[41566 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Geo_tagged/2020_5.csv')\n",
    "df_tweet = pd.DataFrame()\n",
    "df_tweet['time']  = df['created_at']\n",
    "df_tweet[\"Tweets\"] = df[\"full_text\"]\n",
    "df_tweet['id'] = df['id_str']\n",
    "df_tweet['place'] = df['place']\n",
    "df_tweet=df_tweet.drop_duplicates()\n",
    "df_tweet"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training_CT_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "062d3b870c3a4d2c96b7588ebec4f917": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "120a22ff51a64b41a76f3a5f2a818caf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17bd8df397a0459a8e5e577ad4705463",
       "IPY_MODEL_b3d42861496b4b03bfe2d5b2a32b4c9e"
      ],
      "layout": "IPY_MODEL_3fc5718a054c43d5b6644aef9e69b42a"
     }
    },
    "17bd8df397a0459a8e5e577ad4705463": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d669d1ac02c491c877426c4c4f1ea75",
      "max": 421,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7eda40dd90694167a4f9f476356b4487",
      "value": 421
     }
    },
    "28242db0cd1044a9b062f3de4f8ce72e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fc5718a054c43d5b6644aef9e69b42a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4da1f5737edf487bbd8f1c4f280a16ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ac8c2735ef44c36948f63a0bf37b285": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bc583f88db94e6385660975ec21df00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b816512135bb42a08a63e5a45d22efee",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1132d7d1c7d4402b3a6fdc86e9f4e44",
      "value": 231508
     }
    },
    "6014e60b9b5d4337b2c94c372c7f53f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d669d1ac02c491c877426c4c4f1ea75": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eda40dd90694167a4f9f476356b4487": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b3d42861496b4b03bfe2d5b2a32b4c9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6014e60b9b5d4337b2c94c372c7f53f5",
      "placeholder": "​",
      "style": "IPY_MODEL_5ac8c2735ef44c36948f63a0bf37b285",
      "value": " 421/421 [00:02&lt;00:00, 199B/s]"
     }
    },
    "b816512135bb42a08a63e5a45d22efee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b98b32da9cc84d55a5d85eb7d2940717": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5bc583f88db94e6385660975ec21df00",
       "IPY_MODEL_ccf6ae8bd9af406fb0eb91d2a18d062e"
      ],
      "layout": "IPY_MODEL_4da1f5737edf487bbd8f1c4f280a16ae"
     }
    },
    "ccf6ae8bd9af406fb0eb91d2a18d062e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28242db0cd1044a9b062f3de4f8ce72e",
      "placeholder": "​",
      "style": "IPY_MODEL_062d3b870c3a4d2c96b7588ebec4f917",
      "value": " 232k/232k [00:01&lt;00:00, 164kB/s]"
     }
    },
    "f1132d7d1c7d4402b3a6fdc86e9f4e44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
